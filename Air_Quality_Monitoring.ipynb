!pip install gspread

import gspread
from google.auth import default
# Authenticate and authorize access
creds, _ = default()
gc = gspread.authorize(creds)



import gspread
import pandas as pd
from oauth2client.service_account import ServiceAccountCredentials

# Define the scope for Google Sheets and Google Drive APIs
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]

# Load credentials from the JSON key file
creds = ServiceAccountCredentials.from_json_keyfile_name("/content/glossy-premise-408811-fa45e81faf35.json", scope)

# Authenticate with Google Sheets
gc = gspread.authorize(creds)

# Open the Google Sheet by URL
sheet_url = 'https://docs.google.com/spreadsheets/d/1PXHUDPv1E5qPUqin0HKNC6h-UrF0j1_RJ9BnoS20gic/edit?gid=0#gid=0'
sheet = gc.open_by_url(sheet_url).sheet1

# Fetch all records
data = sheet.get_all_records()

# Load data into a pandas DataFrame
df = pd.DataFrame(data)

# Display the first few rows
print(df.head())

import pandas as pd

def fetch_data(sheet):
    # Fetch all records from Google Sheets
    data = sheet.get_all_records()
    # Convert the data to a DataFrame
    df = pd.DataFrame(data)
    # Optionally, convert the Timestamp column to datetime format
    if 'Timestamp' in df.columns:
        df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    return df


import time

# Fetch the initial data
df = fetch_data(sheet)
print("Initial data:")
print(df)

# Loop to continuously fetch updated data
while True:
    # Fetch the latest data
    df = fetch_data(sheet)

    # Clear previous output and display the updated data
    from IPython.display import clear_output
    clear_output(wait=True)

    # Display the latest data
    print("Updated data:")
    print(df.tail())  # Show only the last few rows for clarity

    # Add a delay to match the ESP8266 update frequency (e.g., 5 seconds)
    time.sleep(5)



# Assuming `sheet` is already defined and authorized in Colab
import pandas as pd

# Fetch data
data = sheet.get_all_records()
df = pd.DataFrame(data)

# Convert timestamp to datetime format if not done already
df['Timestamp'] = pd.to_datetime(df['Timestamp'])


def classify_air_quality(pm2_5, pm10):
    if pm2_5 <= 30 and pm10 <= 50:
        return 'Good'
    elif pm2_5 <= 60 and pm10 <= 100:
        return 'Satisfactory'
    elif pm2_5 <= 90 and pm10 <= 250:
        return 'Moderately Polluted'
    elif pm2_5 <= 120 and pm10 <= 350:
        return 'Poor'
    elif pm2_5 <= 250 and pm10 <= 430:
        return 'Very Poor'
    else:
        return 'Severe'


import pandas as pd
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np

# Define the classify_air_quality function
def classify_air_quality(pm2_5, pm10):
    if pm2_5 <= 30 and pm10 <= 50:
        return 'Good'
    elif pm2_5 <= 60 and pm10 <= 100:
        return 'Satisfactory'
    elif pm2_5 <= 90 and pm10 <= 250:
        return 'Moderately Polluted'
    elif pm2_5 <= 120 and pm10 <= 350:
        return 'Poor'
    elif pm2_5 <= 250 and pm10 <= 430:
        return 'Very Poor'
    else:
        return 'Severe'

# Define a function to perform anomaly detection and classification in Colab without modifying the sheet
def perform_analysis(df):
    # Apply classification to each row
    df['AirQualityCategory'] = df.apply(lambda row: classify_air_quality(row['PM2_5'], row['PM10']), axis=1)

    # Anomaly Detection using Isolation Forest
    features = df[['PM1_0', 'PM2_5', 'PM10']]
    iso_forest = IsolationForest(contamination=0.05, random_state=42)
    anomalies = iso_forest.fit_predict(features)
    df['Anomaly'] = np.where(anomalies == -1, 'Yes', 'No')  # Label anomalies as 'Yes' or 'No'

    # Train a classifier for Air Quality Category
    X = df[['PM1_0', 'PM2_5', 'PM10']]
    y = df['AirQualityCategory']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train Random Forest Classifier
    classifier = RandomForestClassifier(random_state=42)
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)

    # Accuracy and Classification Report
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model Accuracy: {accuracy * 100:.2f}%\n")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    # Summary of Results
    print("\n### Summary of Air Quality Analysis ###")
    print(f"Total data points: {len(df)}")
    print(f"Anomalies detected: {df['Anomaly'].value_counts()['Yes']} out of {len(df)} ({(df['Anomaly'].value_counts()['Yes'] / len(df) * 100):.2f}%)")

    print("\n### Air Quality Category Distribution ###")
    category_counts = df['AirQualityCategory'].value_counts()
    for category, count in category_counts.items():
        print(f"{category}: {count} ({(count / len(df) * 100):.2f}%)")

    # Select random 50% of the data while ensuring anomalies are included
    anomalies_df = df[df['Anomaly'] == 'Yes']
    non_anomalies_df = df[df['Anomaly'] == 'No'].sample(frac=0.5, random_state=42)
    report_df = pd.concat([anomalies_df, non_anomalies_df]).sample(frac=1, random_state=42).reset_index(drop=True)

    # Display a formatted table
    display_formatted_table(report_df)

    # Generate individual plots for PM1.0, PM2.5, and PM10
    plot_pm_levels(df, 'PM1_0', 'PM1.0', '#8E44AD', '#E74C3C', 'PM1.0')
    plot_pm_levels(df, 'PM2_5', 'PM2.5', '#2980B9', '#F39C12', 'PM2.5')
    plot_pm_levels(df, 'PM10', 'PM10', '#27AE60', '#D35400', 'PM10')

# Define a function to display the report as a beautifully formatted table
def display_formatted_table(report_df):
    # Apply styles to highlight anomalies and color-code categories
    def color_anomalies(val):
        return 'background-color: #ffcccc' if val == 'Yes' else ''

    def color_categories(val):
        colors = {
            'Good': '#d4edda',
            'Satisfactory': '#c3e6cb',
            'Moderately Polluted': '#ffeeba',
            'Poor': '#f5c6cb',
            'Very Poor': '#f8d7da',
            'Severe': '#f5b7b1'
        }
        return f'background-color: {colors.get(val, "")}'

    styled_df = report_df.style.applymap(color_anomalies, subset=['Anomaly']).applymap(color_categories, subset=['AirQualityCategory']) \
        .set_properties(**{'border': '1px solid black', 'padding': '5px'}).set_table_styles(
        [{'selector': 'th', 'props': [('background-color', '#f2f2f2'), ('color', '#333'), ('font-weight', 'bold')]}]
    ).set_caption("Air Quality Monitoring Report (Random 50% Sample)")

    # Display the styled DataFrame
    display(styled_df)

# Function to create individual plots for each PM level
def plot_pm_levels(df, pm_column, pm_label, color_line, color_anomaly, title):
    plt.figure(figsize=(15, 6))

    # Plot PM level with line and markers
    plt.plot(df['Timestamp'], df[pm_column], label=pm_label, color=color_line, marker='o', markersize=4, linestyle='-', linewidth=1.5)

    # Highlight anomalies
    plt.scatter(df.loc[df['Anomaly'] == 'Yes', 'Timestamp'], df.loc[df['Anomaly'] == 'Yes', pm_column],
                color=color_anomaly, label=f'{pm_label} Anomalies', marker='x', s=100, zorder=5)

    # Enhance the plot aesthetics
    plt.title(f'{title} Levels with Anomaly Detection', fontsize=16, weight='bold')
    plt.xlabel('Timestamp', fontsize=14)
    plt.ylabel('Concentration (µg/m³)', fontsize=14)
    plt.grid(visible=True, color='gray', linestyle='--', linewidth=0.5, alpha=0.7)
    plt.xticks(rotation=45)
    plt.yticks(fontsize=12)

    # Format x-axis for dates for better readability
    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=1))  # Adjust interval as needed
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))

    # Add a legend with a styled background
    plt.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, framealpha=0.9, shadow=True, borderpad=1)

    # Show the plot with improved style
    plt.tight_layout()
    plt.show()

# Fetch data from Google Sheets (assuming `sheet` is already defined)
data = sheet.get_all_records()
df = pd.DataFrame(data)

# Convert timestamp to datetime if necessary
df['Timestamp'] = pd.to_datetime(df['Timestamp'])

# Run the analysis
perform_analysis(df)

import gspread
import pandas as pd
import numpy as np
from oauth2client.service_account import ServiceAccountCredentials

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

import matplotlib.pyplot as plt
import seaborn as sns

# -------------------------------------------------------------------
# 1. Connect to Google Sheets and Fetch Data
# -------------------------------------------------------------------
def get_dataframe_from_sheets(json_keyfile_path, sheet_url):
    """
    Connect to Google Sheets using a service account JSON keyfile and fetch data.
    Returns a pandas DataFrame with a parsed Timestamp column.
    """
    scope = ["https://spreadsheets.google.com/feeds",
             "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scope)
    gc = gspread.authorize(creds)
    sheet = gc.open_by_url(sheet_url).sheet1  # or select another worksheet if needed
    data = sheet.get_all_records()

    df = pd.DataFrame(data)
    # Convert Timestamp column to datetime if it exists
    if 'Timestamp' in df.columns:
        df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    return df

# -------------------------------------------------------------------
# 2. Define Air Quality Classification Logic
# -------------------------------------------------------------------
def classify_air_quality(pm2_5, pm10):
    """
    Returns a string label for air quality based on PM2.5 and PM10.
    """
    if pm2_5 <= 30 and pm10 <= 50:
        return 'Good'
    elif pm2_5 <= 60 and pm10 <= 100:
        return 'Satisfactory'
    elif pm2_5 <= 90 and pm10 <= 250:
        return 'Moderately Polluted'
    elif pm2_5 <= 120 and pm10 <= 350:
        return 'Poor'
    elif pm2_5 <= 250 and pm10 <= 430:
        return 'Very Poor'
    else:
        return 'Severe'

# -------------------------------------------------------------------
# 3. Train a Random Forest Classifier
# -------------------------------------------------------------------
def train_air_quality_model(df):
    """
    - Creates an 'AirQualityCategory' column using classify_air_quality.
    - Trains a Random Forest classifier to predict the category from PM1_0, PM2_5, PM10.
    - Returns the trained model, X_test, y_test, and predictions.
    """
    # Ensure PM columns exist
    for col in ['PM1_0', 'PM2_5', 'PM10']:
        if col not in df.columns:
            raise ValueError(f"Missing column: {col}")

    # Create the label
    df['AirQualityCategory'] = df.apply(lambda row: classify_air_quality(row['PM2_5'], row['PM10']), axis=1)

    # Prepare features (X) and target (y)
    X = df[['PM1_0', 'PM2_5', 'PM10']].copy()
    y = df['AirQualityCategory'].copy()

    # Encode string labels numerically for classification
    encoder = LabelEncoder()
    y_encoded = encoder.fit_transform(y)

    # Split into train/test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42
    )

    # Train a Random Forest
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)

    # Predict on the test set
    y_pred = rf.predict(X_test)

    return rf, X_test, y_test, y_pred, encoder

def plot_six_figures(df, model, X_test, y_test, y_pred, encoder):
    """
    Produce six separate plots to give a comprehensive overview of data and model performance.
    """
    # --------------------------------------------
    # A. Prepare Data for Plotting
    # --------------------------------------------
    # Create a combined DataFrame for test data
    results_df = X_test.copy()
    results_df['ActualCategory'] = encoder.inverse_transform(y_test)
    results_df['PredictedCategory'] = encoder.inverse_transform(y_pred)

    # Higher DPI for HD clarity
    plt.rcParams['figure.dpi'] = 150

    # --------------------------------------------
    # Plot 1: Time-series of PM Levels (if Timestamp available)
    # --------------------------------------------
    if 'Timestamp' in df.columns:
        plt.figure(figsize=(10, 5))
        plt.plot(df['Timestamp'], df['PM1_0'], label='PM1.0', color='blue')
        plt.plot(df['Timestamp'], df['PM2_5'], label='PM2.5', color='red')
        plt.plot(df['Timestamp'], df['PM10'], label='PM10', color='green')
        plt.xlabel('Timestamp')
        plt.ylabel('Concentration (µg/m³)')
        plt.title('Time-Series of PM1.0, PM2.5, and PM10')
        plt.legend()
        plt.tight_layout()
        plt.show()

    # --------------------------------------------
    # Plot 2: Distribution of PM1.0, PM2.5, PM10
    # --------------------------------------------
    plt.figure(figsize=(10, 5))
    sns.histplot(df['PM1_0'], color='blue', kde=True, label='PM1.0', alpha=0.5)
    sns.histplot(df['PM2_5'], color='red', kde=True, label='PM2.5', alpha=0.5)
    sns.histplot(df['PM10'], color='green', kde=True, label='PM10', alpha=0.5)
    plt.title('Distribution of PM1.0, PM2.5, and PM10')
    plt.xlabel('Concentration (µg/m³)')
    plt.ylabel('Count')
    plt.legend()
    plt.tight_layout()
    plt.show()

    # --------------------------------------------
    # Plot 3: Correlation Heatmap
    # --------------------------------------------
    plt.figure(figsize=(6, 5))
    corr_matrix = df[['PM1_0','PM2_5','PM10']].corr()
    sns.heatmap(corr_matrix, annot=True, cmap='Blues', fmt=".2f")
    plt.title('Correlation Heatmap for PM Values')
    plt.tight_layout()
    plt.show()

    # --------------------------------------------
    # Plot 4: Confusion Matrix
    # --------------------------------------------
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',
                xticklabels=encoder.classes_,
                yticklabels=encoder.classes_)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Category')
    plt.ylabel('Actual Category')
    plt.tight_layout()
    plt.show()

    # --------------------------------------------
    # Plot 5: Feature Importance (Random Forest)
    # --------------------------------------------
    plt.figure(figsize=(6, 5))
    importances = model.feature_importances_
    feature_names = X_test.columns
    sns.barplot(x=importances, y=feature_names, palette='viridis')
    plt.title('Feature Importance in Random Forest')
    plt.xlabel('Relative Importance')
    plt.tight_layout()
    plt.show()

    # --------------------------------------------
    # Plot 6: Actual vs Predicted Category Counts
    # --------------------------------------------
    plt.figure(figsize=(8, 5))
    actual_counts = results_df['ActualCategory'].value_counts()
    pred_counts = results_df['PredictedCategory'].value_counts()

    # Ensure all categories appear in both
    all_cats = sorted(set(encoder.classes_))
    actual_vals = [actual_counts.get(cat, 0) for cat in all_cats]
    pred_vals = [pred_counts.get(cat, 0) for cat in all_cats]

    x = np.arange(len(all_cats))
    width = 0.35

    plt.bar(x - width/2, actual_vals, width, label='Actual', color='steelblue')
    plt.bar(x + width/2, pred_vals, width, label='Predicted', color='darkorange')

    plt.xticks(x, all_cats, rotation=45)
    plt.title('Actual vs. Predicted Category Counts')
    plt.xlabel('Air Quality Category')
    plt.ylabel('Count')
    plt.legend()
    plt.tight_layout()
    plt.show()

def main():
    # Update the path to your JSON keyfile and the URL of your Google Sheet
    json_keyfile_path = "/content/glossy-premise-408811-fa45e81faf35.json"
    sheet_url = "https://docs.google.com/spreadsheets/d/1PXHUDPv1E5qPUqin0HKNC6h-UrF0j1_RJ9BnoS20gic/edit?usp=sharing"

    # 1) Fetch Data
    df = get_dataframe_from_sheets(json_keyfile_path, sheet_url)
    print("Data Snapshot:")
    print(df.head())

    # 2) Train Model
    model, X_test, y_test, y_pred, encoder = train_air_quality_model(df)

    # 3) Display Evaluation
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=encoder.classes_))

    # 4) Generate 6 HD Plots
    plot_six_figures(df, model, X_test, y_test, y_pred, encoder)

# Run the end-to-end pipeline (comment out if you only want to import functions above)
if __name__ == "__main__":
    main()

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

def classify_air_quality(pm2_5, pm10):
    if pm2_5 <= 30 and pm10 <= 50:
        return 'Good'
    elif pm2_5 <= 60 and pm10 <= 100:
        return 'Satisfactory'
    elif pm2_5 <= 90 and pm10 <= 250:
        return 'Moderately Polluted'
    elif pm2_5 <= 120 and pm10 <= 350:
        return 'Poor'
    elif pm2_5 <= 250 and pm10 <= 430:
        return 'Very Poor'
    else:
        return 'Severe'

# Create the AirQualityCategory column
df['AirQualityCategory'] = df.apply(lambda row: classify_air_quality(row['PM2_5'], row['PM10']), axis=1)

# Prepare features and target
X = df[['PM1_0', 'PM2_5', 'PM10']]
y = df['AirQualityCategory']

# Encode the target labels into numbers
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42
)

# Train a Random Forest Classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf.predict(X_test)

# Create a DataFrame to display actual vs predicted values
results_df = X_test.copy()
results_df['ActualCategory'] = encoder.inverse_transform(y_test)
results_df['PredictedCategory'] = encoder.inverse_transform(y_pred)

print("Predicted vs. Actual Values (Test Set):")
print(results_df.head())

print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=encoder.classes_))




